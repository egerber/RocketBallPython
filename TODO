
  TODO:
  - generate good trainigdata for forward model 2
  - train rocketBall with non zero initial state
  - change move() procedures to take arrays
  - select available configurations from list and create corresponding path automatically
  - change log strategy of forward Model to save less datapoints

QUESTION:
- Why is the error displayed in tensorboard always by several magnitudes higher than the error displayed in the commandline after each training cycle
-> probably the error in the command window is wrong because the results are usually not as good as they should.


QUESTIONS:
- why is the plotted error so low but the performance so bad?

INSIGHTS:
- in some configurations, particular obstacles are not seen when coming from a particular position. This is probably because in the training data there are few cases for this exact movement.
-> try with less obstacles


INSIGHTS
- Batchsize=1 works best
- learningrate 0.0001 and 0.001 does not work well
- learningrate 0.01 works best
- best configuration: learning on various obstacle configur
- If fixed size of obstacle is trained, change in number of obstacles results in shifted predictions

Vorschlag Herr Butz:
-> zuerst Dikstra Pfadalgorithmus, danach im lokalen Umfeld minimieren

How to structure BA?
-> Introduction to NN
    -> LSTMs and formulas
-> rocketBall scenario
-> previous attempts
-> hierarchical approach


TOOD heute:
-test trained multilayer lstms
    -> sensor version
    -> no sensor version
- if results are not good enough, try training with different parameters (network size, batchsize,learning_rate,count_timesteps)


INSIGHTS
- training on 500_100_50 works perfekt with 2 layers (16,0.01), maybe less timesteps have to be trained
- 10000_1 does not work well but 500_100_10
- maybe less configu

TODO
-train on 50000_1 and compare with 10000
- determine whether count_configurations or count_trainings is more important
- change name of last_speed etc. - last speed -> last_state, last_state-> state
